{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two line logging in ML Flow\n",
    "`import mlflow\n",
    "mlflow.sklearn.autolog(log_input_examples=True, log_model_signatures=True)\n",
    "!mlflow ui`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression on example of boston data without mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.4 ms ± 4.34 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 #-o\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = boston.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train model, get predictions\n",
    "reg = Ridge()\n",
    "reg.fit(X, y)\n",
    "y_pred = reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression on example of boston data with mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog(log_input_examples=True, log_model_signatures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 ms ± 10.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 #-o\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = boston.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train model, get predictions\n",
    "reg = Ridge()\n",
    "reg.fit(X, y)\n",
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification using Random Forest on the example of iris data without mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog(disable=True)\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from numpy.random.mtrand import permutation\n",
    "from sklearn.datasets import load_iris\n",
    "import scikitplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 ms ± 32.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 #-o\n",
    "\n",
    "# load data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "labels = iris.target_names\n",
    "features = iris.feature_names\n",
    "\n",
    "#y[y != 0] = 1\n",
    "\n",
    "# shuffle data\n",
    "X, y = shuffle(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# create model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_test)\n",
    "y_probas = model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "#scikitplot.metrics.plot_roc(y_test, y_probas);\n",
    "#scikitplot.metrics.plot_precision_recall(y_test, y_probas);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification using Random Forest on the example of iris data with mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog(log_input_examples=True, log_model_signatures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932 ms ± 239 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 #-o\n",
    "# load data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "labels = iris.target_names\n",
    "features = iris.feature_names\n",
    "\n",
    "y[y != 0] = 1.0\n",
    "\n",
    "# shuffle data\n",
    "X, y = shuffle(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# create model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_test)\n",
    "y_probas = model.predict_proba(X_test)\n",
    "\n",
    "#scikitplot.metrics.plot_roc(y_test, y_probas);\n",
    "#scikitplot.metrics.plot_precision_recall(y_test, y_probas);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with KMeans\n",
    "## using iris data without mlflow without autologging: metrics weren't being saved\n",
    "(can add also DBSCAN, AgglomerativeClustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn import datasets, cluster\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import mlflow.sklearn\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "import scikitplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.8 ms ± 1.21 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 #-o\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=21)\n",
    "\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "#scikitplot.cluster.plot_elbow_curve(kmeans, X)\n",
    "#scikitplot.metrics.plot_silhouette(X, cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with KMeans \n",
    "## using iris data with mlflow without autologging: metrics weren't being saved\n",
    "(can add also DBSCAN, AgglomerativeClustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " #mlflow.sklearn.autolog(log_input_examples=True, log_model_signatures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.9 ms ± 4.99 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 #-o\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=21)\n",
    "params = kmeans.get_params()\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    cluster_labels = kmeans.fit_predict(X)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.sklearn.log_model(cluster_labels, artifact_path=\"model1\")\n",
    "    mlflow.log_metric(\"score\", kmeans.score(X), step=None)\n",
    "\n",
    "    #scikitplot.cluster.plot_elbow_curve(kmeans, X)\n",
    "    #scikitplot.metrics.plot_silhouette(X, cluster_labels)\n",
    "    \n",
    "    # Log artifacts (output files) #save plt and then save as artifact.. can't be done directly\n",
    "    #mlflow.log_artifact(\"elbow.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM on iris data without mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog(disable=True)\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.1 ms ± 2.42 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%timeit -n 10 #-o\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "# Fit model\n",
    "svm = SVC(kernel='rbf', random_state=0, gamma=10, C=1)\n",
    "svm.fit(X_train_std, y_train)\n",
    "\n",
    "# Create a matplotlib custom plot to save \n",
    "def plot_data():\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    markers = ('s', 'x', 'o')\n",
    "    colors = ('red', 'blue', 'lightgreen')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y_test))])\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "               c=cmap(idx), marker=markers[idx], label=cl)\n",
    "\n",
    "\n",
    "plot_data()\n",
    "\n",
    "#### get the whole list of the parameters for the run for the estimator (if we are not logging it inside the loop)param_config = svm.get_params()\n",
    "#param_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM on iris data with mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog(log_input_examples=True, log_model_signatures=True)\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253 ms ± 24 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%timeit -n 10 #-o\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "# Fit model\n",
    "svm = SVC(kernel='rbf', random_state=0, gamma=10, C=1)\n",
    "svm.fit(X_train_std, y_train)\n",
    "\n",
    "# Create a matplotlib custom plot to save \n",
    "def plot_data():\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    markers = ('s', 'x', 'o')\n",
    "    colors = ('red', 'blue', 'lightgreen')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y_test))])\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "               c=cmap(idx), marker=markers[idx], label=cl)\n",
    "\n",
    "\n",
    "plot_data()\n",
    "\n",
    "#### get the whole list of the parameters for the run for the estimator (if we are not logging it inside the loop)param_config = svm.get_params()\n",
    "#param_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from itertools import cycle, islice\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulsar stars detection: clustering, classification, ridge regression with mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog(log_input_examples=True, log_model_signatures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "pulsar = pd.read_csv('data/pulsar_stars.csv')\n",
    "\n",
    "# Get numeric labels for each of the string labels, to make them compatible with our model\n",
    "labels_to_class = {'Pulsar': 0, 'Not a Pulsar': 1}\n",
    "def get_class_ids(labels):\n",
    "    return np.array([labels_to_class[alabel] for alabel in labels])\n",
    "def get_named_labels(labels, numeric_labels):\n",
    "        return np.array([labels[num_label] for num_label in numeric_labels])\n",
    "\n",
    "# Remove target variables label (and class)\n",
    "features = list(set(pulsar.columns) - {'target_class'})\n",
    "X = pulsar[features]\n",
    "y = pulsar['target_class']\n",
    "labels = ['Pulsar', 'Not a Pulsar']\n",
    "X = X[:50000]\n",
    "y = y[:50000]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "features_scaled = scaler.fit_transform(X)\n",
    "# Split into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=False)\n",
    "\n",
    "# Clustering - predict particle clusters without labels\n",
    "# KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=1)\n",
    "cluster_labels = kmeans.fit_predict(X_train)\n",
    "label_names = get_named_labels(labels, cluster_labels)\n",
    "\n",
    "# Classification - predict pulsar\n",
    "# Train a model, get predictions\n",
    "log = lm.LogisticRegression(random_state=4)\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "dtree = DecisionTreeClassifier(random_state=4)\n",
    "rtree = RandomForestClassifier(n_estimators=100, random_state=4)\n",
    "svm = SVC(random_state=4, probability=True)\n",
    "nb = GaussianNB()\n",
    "gbc = GradientBoostingClassifier()\n",
    "adaboost = AdaBoostClassifier(n_estimators=500, learning_rate=0.01, random_state=42,\n",
    "                             base_estimator=DecisionTreeClassifier(max_depth=8,\n",
    "                             min_samples_leaf=10, random_state=42))\n",
    "\n",
    "def model_algorithm(clf, X_train, y_train, X_test, y_test, name, labels, features):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_probas = clf.predict_proba(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "model_algorithm(log, X_train, y_train, X_test, y_test, 'LogisticRegression', labels, features)\n",
    "model_algorithm(knn, X_train, y_train, X_test, y_test, 'KNearestNeighbor', labels, features)\n",
    "model_algorithm(dtree, X_train, y_train, X_test, y_test, 'DecisionTree', labels, features)\n",
    "model_algorithm(rtree, X_train, y_train, X_test, y_test, 'RandomForest', labels, features)\n",
    "model_algorithm(svm, X_train, y_train, X_test, y_test, 'SVM', labels, features)\n",
    "model_algorithm(nb, X_train, y_train, X_test, y_test, 'NaiveBayes', labels, features)\n",
    "model_algorithm(adaboost, X_train, y_train, X_test, y_test, 'AdaBoost', labels, features)\n",
    "model_algorithm(gbc, X_train, y_train, X_test, y_test, 'GradientBoosting', labels, features)\n",
    "\n",
    "# Regression - TrackP - particle momentum\n",
    "features = list(set(pulsar.columns) - {' Mean of the integrated profile'})\n",
    "X = pulsar[features]\n",
    "y = pulsar[' Mean of the integrated profile']\n",
    "X = X[:10000]\n",
    "y = y[:10000]\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.90, test_size=0.10)\n",
    "\n",
    "# Train a model, get predictions\n",
    "reg = Ridge()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic data: clustering, classification and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from itertools import cycle, islice\n",
    "from sklearn.neighbors import BallTree, KDTree, DistanceMetric\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Load data\n",
    "pulsar = pd.read_csv('/data/titanic-train.csv')\n",
    "\n",
    "# Get numeric labels for each of the string labels, to make them compatible with our model\n",
    "labels_to_class = {'Did not Survive': 0, 'Survived': 1}\n",
    "def get_class_ids(labels):\n",
    "    return np.array([labels_to_class[alabel] for alabel in labels])\n",
    "def get_named_labels(labels, numeric_labels):\n",
    "        return np.array([labels[num_label] for num_label in numeric_labels])\n",
    "\n",
    "# Remove target variables label (and class)\n",
    "features = list(set(pulsar.columns) - {'Survived','Name'})\n",
    "X = pulsar[features]\n",
    "y = pulsar['Survived']\n",
    "labels = ['Did not Survive', 'Survived']\n",
    "X = X[:50000]\n",
    "X = X.replace(\"\", np.nan, regex = True)\n",
    "y = y[:50000]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "features_scaled = scaler.fit_transform(X)\n",
    "# Split into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=False)\n",
    "\n",
    "# Clustering - predict particle clusters without labels\n",
    "# KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=1)\n",
    "cluster_labels = kmeans.fit_predict(X_train)\n",
    "label_names = get_named_labels(labels, cluster_labels)\n",
    "\n",
    "# Classification - predict pulsar\n",
    "# Train a model, get predictions\n",
    "log = lm.LogisticRegression(random_state=4)\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "dtree = DecisionTreeClassifier(random_state=4)\n",
    "rtree = RandomForestClassifier(n_estimators=100, random_state=4)\n",
    "svm = SVC(random_state=4, probability=True)\n",
    "nb = GaussianNB()\n",
    "gbc = GradientBoostingClassifier()\n",
    "adaboost = AdaBoostClassifier(n_estimators=500, learning_rate=0.01, random_state=42,\n",
    "                             base_estimator=DecisionTreeClassifier(max_depth=8,\n",
    "                             min_samples_leaf=10, random_state=42))\n",
    "\n",
    "def model_algorithm(clf, X_train, y_train, X_test, y_test, name, labels, features):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_probas = clf.predict_proba(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "model_algorithm(log, X_train, y_train, X_test, y_test, 'LogisticRegression', labels, features)\n",
    "model_algorithm(knn, X_train, y_train, X_test, y_test, 'KNearestNeighbor', labels, features)\n",
    "model_algorithm(dtree, X_train, y_train, X_test, y_test, 'DecisionTree', labels, features)\n",
    "model_algorithm(rtree, X_train, y_train, X_test, y_test, 'RandomForest', labels, features)\n",
    "model_algorithm(svm, X_train, y_train, X_test, y_test, 'SVM', labels, features)\n",
    "model_algorithm(nb, X_train, y_train, X_test, y_test, 'NaiveBayes', labels, features)\n",
    "model_algorithm(adaboost, X_train, y_train, X_test, y_test, 'AdaBoost', labels, features)\n",
    "model_algorithm(gbc, X_train, y_train, X_test, y_test, 'GradientBoosting', labels, features)\n",
    "\n",
    "# Regression - TrackP - particle momentum\n",
    "features = list(set(pulsar.columns) - {'Age'})\n",
    "X = pulsar[features]\n",
    "y = pulsar['Age']\n",
    "X = X[:10000]\n",
    "y = y[:10000]\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.90, test_size=0.10)\n",
    "\n",
    "# Train a model, get predictions\n",
    "reg = Ridge()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier on tweets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scikitplot\n",
    "        \n",
    "def plot(nb, X_test, y_test, y_probas, y_pred):\n",
    "        scikitplot.estimators.plot_learning_curve(nb, X_test, y_test)\n",
    "        scikitplot.metrics.plot_roc(y_test, y_probas)\n",
    "        scikitplot.metrics.plot_confusion_matrix(y_test, y_pred, labels=nb.classes_)\n",
    "        scikitplot.metrics.plot_precision_recall(y_test, y_probas)\n",
    "\n",
    "\n",
    "def tweets():\n",
    "\n",
    "    # Get a pandas DataFrame object of all the data in the csv file:\n",
    "    df = pd.read_csv('data/tweets.csv')\n",
    "\n",
    "    # Get pandas Series object of the \"tweet text\" column:\n",
    "    text = df['tweet_text']\n",
    "\n",
    "    # Get pandas Series object of the \"emotion\" column:\n",
    "    target = df['is_there_an_emotion_directed_at_a_brand_or_product']\n",
    "\n",
    "    # Remove the blank rows from the series:\n",
    "    target = target[pd.notnull(text)]\n",
    "    text = text[pd.notnull(text)]\n",
    "\n",
    "    # Perform feature extraction:\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    count_vect = CountVectorizer()\n",
    "    count_vect.fit(text)\n",
    "    counts = count_vect.transform(text)\n",
    "\n",
    "\n",
    "    counts_train = counts[:6000]\n",
    "    target_train = target[:6000]\n",
    "    counts_test = counts[6000:]\n",
    "    target_test = target[6000:]\n",
    "\n",
    "\n",
    "    # Train with this data with a Naive Bayes classifier:\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(counts, target)\n",
    "\n",
    "\n",
    "    X_test = counts_test\n",
    "    y_test = target_test\n",
    "    y_probas = nb.predict_proba(X_test)\n",
    "    y_pred = nb.predict(X_test)\n",
    "\n",
    "    #print(\"y\", y_probas.shape)\n",
    "    #plot(nb, X_test, y_test, y_probas, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# without mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10 #-o\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "tweets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10 #-o\n",
    "mlflow.sklearn.autolog(log_input_examples=True, log_model_signatures=True)\n",
    "tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mlflow ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
